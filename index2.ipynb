{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573ba477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For our modeling steps\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "\n",
    "# For demonstrative purposes\n",
    "from scipy.special import logit, expit\n",
    "from sklearn import datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c4fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df = pd.read_csv('Data/Traffic_Crashes_-_Crashes.csv', low_memory=False)\n",
    "people_df = pd.read_csv('Data/Traffic_Crashes_-_People.csv', low_memory=False)\n",
    "vehicles_df = pd.read_csv('Data/Traffic_Crashes_-_Vehicles.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8245ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 767532 entries, 0 to 767531\n",
      "Data columns (total 49 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   CRASH_RECORD_ID                767532 non-null  object \n",
      " 1   RD_NO                          763205 non-null  object \n",
      " 2   CRASH_DATE_EST_I               57802 non-null   object \n",
      " 3   CRASH_DATE                     767532 non-null  object \n",
      " 4   POSTED_SPEED_LIMIT             767532 non-null  int64  \n",
      " 5   TRAFFIC_CONTROL_DEVICE         767532 non-null  object \n",
      " 6   DEVICE_CONDITION               767532 non-null  object \n",
      " 7   WEATHER_CONDITION              767532 non-null  object \n",
      " 8   LIGHTING_CONDITION             767532 non-null  object \n",
      " 9   FIRST_CRASH_TYPE               767532 non-null  object \n",
      " 10  TRAFFICWAY_TYPE                767532 non-null  object \n",
      " 11  LANE_CNT                       199005 non-null  float64\n",
      " 12  ALIGNMENT                      767532 non-null  object \n",
      " 13  ROADWAY_SURFACE_COND           767532 non-null  object \n",
      " 14  ROAD_DEFECT                    767532 non-null  object \n",
      " 15  REPORT_TYPE                    745404 non-null  object \n",
      " 16  CRASH_TYPE                     767532 non-null  object \n",
      " 17  INTERSECTION_RELATED_I         175817 non-null  object \n",
      " 18  NOT_RIGHT_OF_WAY_I             35637 non-null   object \n",
      " 19  HIT_AND_RUN_I                  239685 non-null  object \n",
      " 20  DAMAGE                         767532 non-null  object \n",
      " 21  DATE_POLICE_NOTIFIED           767532 non-null  object \n",
      " 22  PRIM_CONTRIBUTORY_CAUSE        767532 non-null  object \n",
      " 23  SEC_CONTRIBUTORY_CAUSE         767532 non-null  object \n",
      " 24  STREET_NO                      767532 non-null  int64  \n",
      " 25  STREET_DIRECTION               767528 non-null  object \n",
      " 26  STREET_NAME                    767531 non-null  object \n",
      " 27  BEAT_OF_OCCURRENCE             767527 non-null  float64\n",
      " 28  PHOTOS_TAKEN_I                 9876 non-null    object \n",
      " 29  STATEMENTS_TAKEN_I             16721 non-null   object \n",
      " 30  DOORING_I                      2369 non-null    object \n",
      " 31  WORK_ZONE_I                    4449 non-null    object \n",
      " 32  WORK_ZONE_TYPE                 3463 non-null    object \n",
      " 33  WORKERS_PRESENT_I              1144 non-null    object \n",
      " 34  NUM_UNITS                      767532 non-null  int64  \n",
      " 35  MOST_SEVERE_INJURY             765849 non-null  object \n",
      " 36  INJURIES_TOTAL                 765860 non-null  float64\n",
      " 37  INJURIES_FATAL                 765860 non-null  float64\n",
      " 38  INJURIES_INCAPACITATING        765860 non-null  float64\n",
      " 39  INJURIES_NON_INCAPACITATING    765860 non-null  float64\n",
      " 40  INJURIES_REPORTED_NOT_EVIDENT  765860 non-null  float64\n",
      " 41  INJURIES_NO_INDICATION         765860 non-null  float64\n",
      " 42  INJURIES_UNKNOWN               765860 non-null  float64\n",
      " 43  CRASH_HOUR                     767532 non-null  int64  \n",
      " 44  CRASH_DAY_OF_WEEK              767532 non-null  int64  \n",
      " 45  CRASH_MONTH                    767532 non-null  int64  \n",
      " 46  LATITUDE                       762431 non-null  float64\n",
      " 47  LONGITUDE                      762431 non-null  float64\n",
      " 48  LOCATION                       762431 non-null  object \n",
      "dtypes: float64(11), int64(6), object(32)\n",
      "memory usage: 286.9+ MB\n"
     ]
    }
   ],
   "source": [
    "crashes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2607315",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62043505",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_makes = vehicles_df['MAKE'].unique()\n",
    "print(unique_makes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137db0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_makes = vehicles_df['MAKE'].unique()\n",
    "\n",
    "for make in unique_makes:\n",
    "    print(make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49862383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each unique vehicle make\n",
    "make_counts = vehicles_df['MAKE'].value_counts()\n",
    "\n",
    "# Sort the makes by frequency in descending order\n",
    "sorted_makes = make_counts.sort_values(ascending=False)\n",
    "\n",
    "# Select the top 25 makes\n",
    "top_25_makes = sorted_makes.head(25)\n",
    "\n",
    "# Print the top 25 most frequent makes\n",
    "print(top_25_makes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce9f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have your DataFrame loaded as vehicles_df\n",
    "\n",
    "# Define the top 25 most frequent makes\n",
    "top_25_makes = [\n",
    "    'CHEVROLET', 'UNKNOWN', 'FORD', 'NISSAN', 'HONDA',\n",
    "    'TOYOTA MOTOR COMPANY, LTD.', 'TOYOTA', 'DODGE', 'HYUNDAI', 'JEEP',\n",
    "    'VOLKSWAGEN', 'CHRYSLER', 'BUICK', 'LEXUS', 'KIA', 'MERCEDES-BENZ',\n",
    "    'BMW', 'MAZDA', 'KIA MOTORS CORP', 'CADILLAC', 'INFINITI', 'SUBARU',\n",
    "    'ACURA', 'PONTIAC', 'GENERAL MOTORS CORPORATION (GMC)'\n",
    "]\n",
    "\n",
    "# Create boolean columns for each of the top makes\n",
    "for make in top_25_makes:\n",
    "    vehicles_df[make] = vehicles_df['MAKE'].apply(lambda x: int(x == make))\n",
    "\n",
    "# Use one-hot encoding to convert the boolean columns into binary encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_columns = encoder.fit_transform(vehicles_df[top_25_makes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac79d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_safety = people_df['SAFETY_EQUIPMENT'].unique()\n",
    "\n",
    "for seatbelt in unique_safety:\n",
    "    print(seatbelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db0d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the top 25 most frequent makes\n",
    "top_25_makes = [\n",
    "    'CHEVROLET', 'UNKNOWN', 'FORD', 'NISSAN', 'HONDA',\n",
    "    'TOYOTA MOTOR COMPANY, LTD.', 'TOYOTA', 'DODGE', 'HYUNDAI', 'JEEP',\n",
    "    'VOLKSWAGEN', 'CHRYSLER', 'BUICK', 'LEXUS', 'KIA', 'MERCEDES-BENZ',\n",
    "    'BMW', 'MAZDA', 'KIA MOTORS CORP', 'CADILLAC', 'INFINITI', 'SUBARU',\n",
    "    'ACURA', 'PONTIAC', 'GENERAL MOTORS CORPORATION (GMC)'\n",
    "]\n",
    "\n",
    "# Create boolean columns for each of the top makes\n",
    "for make in top_25_makes:\n",
    "    vehicles_df[make] = vehicles_df['MAKE'].apply(lambda x: int(x == make))\n",
    "\n",
    "# Use one-hot encoding to convert the boolean columns into binary encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_columns = encoder.fit_transform(vehicles_df[top_25_makes])\n",
    "\n",
    "# Fill missing values in 'SAFETY_EQUIPMENT' with \"UNKNOWN\"\n",
    "people_df['SAFETY_EQUIPMENT'].fillna(\"UNKNOWN\", inplace=True)\n",
    "# Create boolean columns for \"SAFETY BELT USED\" and \"SAFETY BELT NOT USED\"\n",
    "people_df['SAFETY_BELT_USED'] = people_df['SAFETY_EQUIPMENT'].str.contains(\"SAFETY BELT USED\", case=False)\n",
    "people_df['SAFETY_BELT_NOT_USED'] = people_df['SAFETY_EQUIPMENT'].str.contains(\"SAFETY BELT NOT USED\", case=False)\n",
    "\n",
    "# Convert the boolean values to 1 (True) and 0 (False)\n",
    "people_df['SAFETY_BELT_USED'] = people_df['SAFETY_BELT_USED'].astype(int)\n",
    "people_df['SAFETY_BELT_NOT_USED'] = people_df['SAFETY_BELT_NOT_USED'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crashes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vehicles_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b404fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'INTERSECTION_RELATED_I',\n",
    "    'NOT_RIGHT_OF_WAY_I',\n",
    "    'HIT_AND_RUN_I',\n",
    "    'DAMAGE',\n",
    "    'DATE_POLICE_NOTIFIED',\n",
    "    'PRIM_CONTRIBUTORY_CAUSE',\n",
    "    'SEC_CONTRIBUTORY_CAUSE',\n",
    "    'STREET_NO',\n",
    "    'STREET_DIRECTION',\n",
    "    'STREET_NAME',\n",
    "    'BEAT_OF_OCCURRENCE',\n",
    "    'PHOTOS_TAKEN_I',\n",
    "    'STATEMENTS_TAKEN_I',\n",
    "    'DOORING_I',\n",
    "    'WORK_ZONE_I',\n",
    "    'WORK_ZONE_TYPE',\n",
    "    'WORKERS_PRESENT_I',\n",
    "    'NUM_UNITS',\n",
    "    'MOST_SEVERE_INJURY',\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'LOCATION'\n",
    "]\n",
    "\n",
    "crashes_df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f702e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a portion of your data\n",
    "sampled_crashes_df = crashes_df.sample(frac=0.1, random_state=42)  # Adjust the fraction as needed\n",
    "\n",
    "# Then perform your merge operations on the sampled data\n",
    "sampled_crashes_df = pd.merge(sampled_crashes_df, vehicles_df, on='CRASH_RECORD_ID', how='left')\n",
    "sampled_crashes_df = pd.merge(sampled_crashes_df, people_df[['CRASH_RECORD_ID', 'SAFETY_BELT_USED', 'SAFETY_BELT_NOT_USED']],\n",
    "                              on='CRASH_RECORD_ID', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be52400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_fraction = 0.1  # 10% of the data\n",
    "\n",
    "# Use the sample method to randomly select a fraction of your data\n",
    "sampled_crashes_df = crashes_df.sample(frac=sample_fraction, random_state=42)  # Set random_state for reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8426fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     70497\n",
      "         1.0       0.00      0.00      0.00        84\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00     70583\n",
      "   macro avg       0.33      0.33      0.33     70583\n",
      "weighted avg       1.00      1.00      1.00     70583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nick\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Handle missing values in sampled_crashes_df\n",
    "sampled_crashes_df['INJURIES_FATAL'].fillna(0, inplace=True)  # Fill missing values in the target variable with 0\n",
    "sampled_crashes_df['MAKE'].fillna('UNKNOWN', inplace=True)    # Fill missing values in 'MAKE' with 'UNKNOWN'\n",
    "\n",
    "# Define your features and target variable\n",
    "features = [\n",
    "    'SAFETY_BELT_USED',\n",
    "    'SAFETY_BELT_NOT_USED',\n",
    "    'CHEVROLET',\n",
    "    'UNKNOWN',\n",
    "    'FORD',\n",
    "    'NISSAN',\n",
    "    'HONDA',\n",
    "    'TOYOTA MOTOR COMPANY, LTD.',\n",
    "    'TOYOTA',\n",
    "    'DODGE',\n",
    "    'HYUNDAI',\n",
    "    'JEEP',\n",
    "    'VOLKSWAGEN',\n",
    "    'CHRYSLER',\n",
    "    'BUICK',\n",
    "    'LEXUS',\n",
    "    'KIA',\n",
    "    'MERCEDES-BENZ',\n",
    "    'BMW',\n",
    "    'MAZDA',\n",
    "    'KIA MOTORS CORP',\n",
    "    'CADILLAC',\n",
    "    'INFINITI',\n",
    "    'SUBARU',\n",
    "    'ACURA',\n",
    "    'PONTIAC',\n",
    "    'GENERAL MOTORS CORPORATION (GMC)'\n",
    "]\n",
    "\n",
    "X = sampled_crashes_df[features]\n",
    "y = sampled_crashes_df['INJURIES_FATAL']\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Drop rows with missing values from both X and y\n",
    "X_train.dropna(inplace=True)\n",
    "y_train = y_train[X_train.index]  # Update y_train to match the modified X_train\n",
    "\n",
    "X_test.dropna(inplace=True)\n",
    "y_test = y_test[X_test.index]  # Update y_test to match the modified X_test\n",
    "\n",
    "# Create and train a logistic regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae99001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef986f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df.INJURY_CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10633b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropna_columns(df, threshold=.8):\n",
    "    '''\n",
    "    Drop columns from a Pandas DataFrame in which more than a certain\n",
    "    percentage (default=80%) of their rows are null/NaN.\n",
    "    '''\n",
    "    return df.dropna(thresh=(((1-threshold) * df.shape[0])) + 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_dropped_df = dropna_columns(crashes_df)\n",
    "people_dropped_df = dropna_columns(people_df)\n",
    "vehicles_dropped_df = dropna_columns(vehicles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1af7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_dropped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a84dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dropped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_dropped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45676e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicles_dropped_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8bc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dropped_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_dropped_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dropped_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "# Identify columns with missing values and their percentages\n",
    "missing_percentage = crashes_df.isnull().mean() * 100\n",
    "\n",
    "# Set a threshold for missing values (e.g., 30%)\n",
    "threshold = 30\n",
    "\n",
    "# Columns with more than the threshold percentage of missing values\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "# Drop columns with high missing values\n",
    "crashes_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# For columns with fewer missing values, you can impute them using the median or mode\n",
    "columns_to_impute = ['LANE_CNT', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I', 'HIT_AND_RUN_I']\n",
    "for column in columns_to_impute:\n",
    "    if column in crashes_df.columns:\n",
    "        if crashes_df[column].dtype == 'float64':\n",
    "            crashes_df[column].fillna(crashes_df[column].median(), inplace=True)\n",
    "        else:\n",
    "            crashes_df[column].fillna(crashes_df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = crashes_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply one-hot encoding to categorical columns with a reasonable number of categories\n",
    "max_categories_for_one_hot = 10  # You can adjust this threshold\n",
    "columns_for_one_hot = [col for col in categorical_columns if len(crashes_df[col].unique()) <= max_categories_for_one_hot]\n",
    "\n",
    "# Apply one-hot encoding to selected categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_columns = pd.DataFrame(encoder.fit_transform(crashes_df[columns_for_one_hot]))\n",
    "encoded_columns.columns = encoder.get_feature_names_out(columns_for_one_hot)\n",
    "\n",
    "# Drop the original categorical columns and concatenate the one-hot encoded columns\n",
    "crashes_df.drop(columns=columns_for_one_hot, inplace=True)\n",
    "crashes_df = pd.concat([crashes_df, encoded_columns], axis=1)\n",
    "\n",
    "# Apply label encoding to remaining categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    if column not in columns_for_one_hot:\n",
    "        crashes_df[column] = label_encoder.fit_transform(crashes_df[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980540b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe23d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values and their percentages\n",
    "missing_percentage = vehicles_df.isnull().mean() * 100\n",
    "\n",
    "# Set a threshold for missing values (e.g., 30%)\n",
    "threshold = 30\n",
    "\n",
    "# Columns with more than the threshold percentage of missing values\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "# Drop columns with high missing values\n",
    "vehicles_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# For columns with fewer missing values, you can impute them using the median or mode\n",
    "columns_to_impute = ['NUM_PASSENGERS', 'CMRC_VEH_I', 'LIC_PLATE_STATE', 'VEHICLE_YEAR']\n",
    "for column in columns_to_impute:\n",
    "    if column in vehicles_df.columns:\n",
    "        if vehicles_df[column].dtype == 'float64':\n",
    "            vehicles_df[column].fillna(vehicles_df[column].median(), inplace=True)\n",
    "        else:\n",
    "            vehicles_df[column].fillna(vehicles_df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = vehicles_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply one-hot encoding to categorical columns with a reasonable number of categories\n",
    "max_categories_for_one_hot = 10  # You can adjust this threshold\n",
    "columns_for_one_hot = [col for col in categorical_columns if len(vehicles_df[col].unique()) <= max_categories_for_one_hot]\n",
    "\n",
    "# Apply one-hot encoding to selected categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_columns = pd.DataFrame(encoder.fit_transform(vehicles_df[columns_for_one_hot]))\n",
    "encoded_columns.columns = encoder.get_feature_names_out(columns_for_one_hot)  # Corrected method name\n",
    "\n",
    "# Drop the original categorical columns and concatenate the one-hot encoded columns\n",
    "vehicles_df.drop(columns=columns_for_one_hot, inplace=True)\n",
    "vehicles_df = pd.concat([vehicles_df, encoded_columns], axis=1)\n",
    "\n",
    "# Apply label encoding to remaining categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    if column not in columns_for_one_hot:\n",
    "        vehicles_df[column] = label_encoder.fit_transform(vehicles_df[column])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53521f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify columns with missing values and their percentages\n",
    "missing_percentage = people_df.isnull().mean() * 100\n",
    "\n",
    "# Set a threshold for missing values (e.g., 30%)\n",
    "threshold = 30\n",
    "\n",
    "# Columns with more than the threshold percentage of missing values\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "# Drop columns with high missing values\n",
    "people_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# For columns with fewer missing values, you can impute them using the median or mode\n",
    "columns_to_impute = ['SEAT_NO', 'CITY', 'STATE', 'ZIPCODE', 'AGE', 'DRIVERS_LICENSE_STATE', 'DRIVERS_LICENSE_CLASS',\n",
    "                     'AIRBAG_DEPLOYED', 'EJECTION', 'HOSPITAL', 'EMS_AGENCY', 'EMS_RUN_NO', 'DRIVER_ACTION',\n",
    "                     'DRIVER_VISION', 'PHYSICAL_CONDITION', 'PEDPEDAL_ACTION', 'PEDPEDAL_VISIBILITY', 'PEDPEDAL_LOCATION',\n",
    "                     'BAC_RESULT', 'BAC_RESULT VALUE', 'CELL_PHONE_USE']\n",
    "for column in columns_to_impute:\n",
    "    if column in people_df.columns:\n",
    "        if people_df[column].dtype == 'float64':\n",
    "            people_df[column].fillna(people_df[column].median(), inplace=True)\n",
    "        else:\n",
    "            people_df[column].fillna(people_df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = people_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply one-hot encoding to categorical columns with a reasonable number of categories\n",
    "max_categories_for_one_hot = 10  # You can adjust this threshold\n",
    "columns_for_one_hot = [col for col in categorical_columns if len(people_df[col].unique()) <= max_categories_for_one_hot]\n",
    "\n",
    "# Apply one-hot encoding to selected categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_columns = pd.DataFrame(encoder.fit_transform(people_df[columns_for_one_hot]))\n",
    "encoded_columns.columns = encoder.get_feature_names_out(columns_for_one_hot)  # Corrected method name\n",
    "\n",
    "# Drop the original categorical columns and concatenate the one-hot encoded columns\n",
    "people_df.drop(columns=columns_for_one_hot, inplace=True)\n",
    "people_df = pd.concat([people_df, encoded_columns], axis=1)\n",
    "\n",
    "# Apply label encoding to remaining categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    if column not in columns_for_one_hot:\n",
    "        people_df[column] = label_encoder.fit_transform(people_df[column])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2792a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca1e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
